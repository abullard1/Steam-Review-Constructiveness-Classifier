{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuned ALBERT Model for Constructiveness Detection in Steam Reviews\n",
        "## *Sentiment-Analysis of Videogame Reviews on the Platform ”Steam” with a Focus on the Detection and Classification of <b>Constructiveness</b>*\n",
        "---\n",
        "### <u>NOTEBOOK **3**/5</u>: This Notebook handles the fine-tuning process using the filtered, preprocessed and annotated Steam Reviews. In this case *bert-base-uncased* is used."
      ],
      "metadata": {
        "id": "knt3UkGsguTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package Installs\n",
        "!pip install -U pip\n",
        "!pip install pandas numpy datasets transformers accelerate scikit-learn tensorboard\n",
        "# Installs TensorFlow from the NVIDIA repo\n",
        "!pip install nvidia-pyindex\n",
        "!pip install nvidia-tensorflow[horovod]\n",
        "# PyTorch with CUDA 12.4 support\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "# Specific version of protobuf (Ensures compatibility with the installed tensorflow version)\n",
        "!pip uninstall -y protobuf\n",
        "!pip install protobuf==3.20.*\n",
        "!pip install -q wandb"
      ],
      "metadata": {
        "id": "bzZUjX0bYH0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "#from google.colab import files\n",
        "import IPython\n",
        "import io\n",
        "import os\n",
        "from datasets import Dataset, DatasetDict\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline, EarlyStoppingCallback\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "import torch, gc\n",
        "import time"
      ],
      "metadata": {
        "id": "xzYr64BNYJcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Flag that automaticaly configures the notebook depending on if it is run in google colab or locally\n",
        "RUNNING_IN_GOOGLE_COLAB = \"google.colab\" in sys.modules\n",
        "print(\"Running in Google Colab\" if RUNNING_IN_GOOGLE_COLAB else \"Running locally\")"
      ],
      "metadata": {
        "id": "aad6j1SsW9z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logs into Weights & Biases Account\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "Uy9rplnxYejl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment variables\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "os.environ[\"WANDB_MODE\"] = \"online\""
      ],
      "metadata": {
        "id": "dvhgkrVYVw-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# System Information\n",
        "# Prints all sorts of system information (CPU, GPU, RAM, CUDA Installed, CUDA Version, RAM) about the google colab runtime\n",
        "print(\"\\033[1m\" + \"GPU Information\" + \"\\033[0m\")\n",
        "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
        "!nvidia-smi\n",
        "print()\n",
        "print(\"\\033[1m\" + \"CPU Information\" + \"\\033[0m\")\n",
        "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
        "!cat /proc/cpuinfo\n",
        "print()\n",
        "print(\"\\033[1m\" + \"Memory Information\" + \"\\033[0m\")\n",
        "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
        "!cat /proc/meminfo\n",
        "print()\n",
        "print(\"\\033[1m\" + \"NVidia CUDA Information\" + \"\\033[0m\")\n",
        "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
        "!nvcc --version\n",
        "print()\n",
        "print(\"\\033[1m\"+ \"CUDA Installation Check\"+ \"\\033[0m\")\n",
        "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "try:\n",
        "  print(\"CUDA Installation Check Result: \" + \"\\033[3m\" + torch.cuda.get_device_name(0) + \"\\033[3m\")\n",
        "except:\n",
        "  if RUNNING_IN_GOOGLE_COLAB:\n",
        "    print(\"No GPU found. You might be connected to a CPU runtime in Google Colab.\")\n",
        "  else:\n",
        "    print(\"No GPU found.\")"
      ],
      "metadata": {
        "id": "puY5fRF82J_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert-base-uncased model architecture\n",
        "from IPython.display import HTML\n",
        "url = \"https://i.ibb.co/YNzJM69/Attention-diagram-transformer.webp\"\n",
        "HTML(f'<img src=\"{url}\" width=\"1000\"/>')"
      ],
      "metadata": {
        "id": "3JuzWtb0hK6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "7787ff92-77a1-4dca-9596-e6024b8cf852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://i.ibb.co/YNzJM69/Attention-diagram-transformer.webp\" width=\"1000\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets seeds for reproducability\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ],
      "metadata": {
        "id": "akTmurPaNG6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and loads the filtered, preprocessed, training-csv to use for the fine-tuning process\n",
        "print(\"Choose .csv to upload for the fine-tuning process...\")\n",
        "#uploaded = files.upload()\n",
        "#filename=[key for key in uploaded.keys()][0]\n",
        "#annotations_df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "#annotations_df.head()\n",
        "annotations_df = pd.read_csv(\"/home/samuel/kaggle/preprocessed_annotations.csv\")\n",
        "annotations_df.head()"
      ],
      "metadata": {
        "id": "w-ebbp7zYZUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2d66ee94-3a27-4962-a8ef-beb2e5d8cd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose .csv to upload for the fine-tuning process...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id      game                                             review  \\\n",
              "0   1  Among Us  This game can suck my balls before I play it a...   \n",
              "1   2  Among Us  Very fun little party game! Even better with f...   \n",
              "2   3  Among Us  if you're lonely don't bother but if you're no...   \n",
              "3   4  Among Us                                   fun and anoyying   \n",
              "4   5  Among Us                            when impostor is sus...   \n",
              "\n",
              "   author_playtime_at_review  voted_up  votes_up  votes_funny  \\\n",
              "0                          6     False         1            0   \n",
              "1                         11      True         0            0   \n",
              "2                         40      True         2            1   \n",
              "3                         80      True         0            0   \n",
              "4                         51      True         0            0   \n",
              "\n",
              "   earnesty_choice  token_count  \n",
              "0                0           22  \n",
              "1                1           24  \n",
              "2                0           27  \n",
              "3                0            5  \n",
              "4                0           10  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>game</th>\n",
              "      <th>review</th>\n",
              "      <th>author_playtime_at_review</th>\n",
              "      <th>voted_up</th>\n",
              "      <th>votes_up</th>\n",
              "      <th>votes_funny</th>\n",
              "      <th>earnesty_choice</th>\n",
              "      <th>token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Among Us</td>\n",
              "      <td>This game can suck my balls before I play it a...</td>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Among Us</td>\n",
              "      <td>Very fun little party game! Even better with f...</td>\n",
              "      <td>11</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Among Us</td>\n",
              "      <td>if you're lonely don't bother but if you're no...</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Among Us</td>\n",
              "      <td>fun and anoyying</td>\n",
              "      <td>80</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Among Us</td>\n",
              "      <td>when impostor is sus...</td>\n",
              "      <td>51</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating the Columns in the Dataset into a String for training like so: Review: {review}, Playtime: {author_playtime_at_review}, Voted Up: {voted_up}, Upvotes: {votes_up}, Votes Funny: {votes_funny}. A new dataframe is created using the columns \"text\" for the concatenated string and \"constructivity\" as the column for \"earnesty_choice\"\n",
        "annotations_df[\"text\"] = annotations_df.apply(lambda row: f'Review: {row[\"review\"]}, Playtime: {row[\"author_playtime_at_review\"]}, Voted Up: {row[\"voted_up\"]}, Upvotes: {row[\"votes_up\"]}, Votes Funny: {row[\"votes_funny\"]}', axis=1)\n",
        "steam_reviews_dataset_df = annotations_df[[\"text\", \"earnesty_choice\"]].rename(columns={\"earnesty_choice\": \"label\"})\n",
        "steam_reviews_dataset_df.head()"
      ],
      "metadata": {
        "id": "lUfDNBvFcFad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "69ff4c30-23cf-4195-b6bf-663ff9407edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Review: This game can suck my balls before I p...      0\n",
              "1  Review: Very fun little party game! Even bette...      1\n",
              "2  Review: if you're lonely don't bother but if y...      0\n",
              "3  Review: fun and anoyying, Playtime: 80, Voted ...      0\n",
              "4  Review: when impostor is sus..., Playtime: 51,...      0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Review: This game can suck my balls before I p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Review: Very fun little party game! Even bette...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Review: if you're lonely don't bother but if y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Review: fun and anoyying, Playtime: 80, Voted ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Review: when impostor is sus..., Playtime: 51,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training_df.to_csv(\"training.csv\", index=False)\n",
        "# files.download(\"training.csv\")"
      ],
      "metadata": {
        "id": "Zkbf3mvLgYik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset onto 80% train, 10% dev and 10% test datasets\n",
        "train_df, test_dev_df = train_test_split(steam_reviews_dataset_df, test_size=0.2, shuffle=True, random_state=42)\n",
        "dev_df, test_df = train_test_split(test_dev_df, test_size=0.5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "XgFIh7KsjGqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)  # Preserve index prevents __index_level_0__ from being added as a column by the \"from_pandas\" method\n",
        "dev_dataset = Dataset.from_pandas(dev_df, preserve_index=False)\n",
        "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)"
      ],
      "metadata": {
        "id": "hBcJUXw7oEQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset_csv = train_df.to_csv(\"./kaggle/train.csv\", index=False)\n",
        "#dev_dataset_csv = dev_dataset.to_csv(\"./kaggle/dev.csv\", index=False)\n",
        "#test_dataset_csv = test_dataset.to_csv(\"./kaggle/test.csv\", index=False)"
      ],
      "metadata": {
        "id": "owWBLjfZVVEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the respective splits into a dictionary for ease-of-use\n",
        "steam_review_dataset_dict = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"dev\": dev_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "print(steam_review_dataset_dict)"
      ],
      "metadata": {
        "id": "kV_SFWkUnVrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847c9fee-a109-403b-f1e9-b74b9160d2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1168\n",
            "    })\n",
            "    dev: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 146\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 147\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steam_review_dataset_dict[\"train\"][0]"
      ],
      "metadata": {
        "id": "-tbQJCRhq9sY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df85939-2385-483e-8302-680dc0041ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Review: Nice coop game, Playtime: 19, Voted Up: True, Upvotes: 0, Votes Funny: 0',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"xlnet-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# tokenizer.pad_token = tokenizer.eos_token  # Used for GPT2 Model"
      ],
      "metadata": {
        "id": "4Wcs8IlSrv56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171a01ae-1a2e-44ac-bc14-d19434dc23e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/samuel/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize function which tokenizes the steam review text\n",
        "def tokenize_function(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "JOGMHQZrrzY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = steam_review_dataset_dict.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "qKWb01qUzHd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65fa722-0310-4119-fe9e-24e63ec5647e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map:   0%|                                      | 0/1168 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Map: 100%|█████████████████████████| 1168/1168 [00:00<00:00, 8347.54 examples/s]\n",
            "Map: 100%|███████████████████████████| 146/146 [00:00<00:00, 8071.60 examples/s]\n",
            "Map: 100%|███████████████████████████| 147/147 [00:00<00:00, 5911.78 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "JJk8DDZttcOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "# model.config.pad_token_id = model.config.eos_token_id  # Used for GPT2 Model"
      ],
      "metadata": {
        "id": "jaFGh2LIujzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a6474b-4f58-429b-eb1a-933d844b3742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"macro\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  precision = precision_score(labels, preds, average=\"macro\")\n",
        "  recall = recall_score(labels, preds, average=\"macro\")\n",
        "  return {\"precision\": precision, \"recall\": recall, \"acc\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "9c892BGux9gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(labels, preds, model_name):\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "67eMmTgxCQTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "model_name = f\"{checkpoint}-finetuned-steam-reviews\"\n",
        "log_dir = \"/home/samuel/kaggle/bert_finetuning_logs/fit\"\n",
        "training_args = TrainingArguments(output_dir = f'/home/samuel/kaggle/finetuned_models/{model_name}',\n",
        "                                  num_train_epochs = 50,\n",
        "                                  fp16=True,\n",
        "                                  seed = 42,  # Seed for reproducability\n",
        "                                  learning_rate = 2e-5,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  eval_strategy=\"epoch\",\n",
        "                                  disable_tqdm = False,\n",
        "                                  logging_steps = 10,\n",
        "                                  logging_dir = log_dir,\n",
        "                                  log_level=\"info\",\n",
        "                                  report_to=[\"wandb\", \"tensorboard\"],\n",
        "                                  save_strategy = \"epoch\",\n",
        "                                  load_best_model_at_end=True)"
      ],
      "metadata": {
        "id": "9GTYhcQ4yD8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes the Trainer with the training arguments\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
        ")"
      ],
      "metadata": {
        "id": "p6bk9T1U2ReR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2aa0ccf-e1bd-4379-f1e9-f224f5a97dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/samuel/.local/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "Using auto half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for xlnet model\n",
        "# for name, param in trainer.model.named_parameters():\n",
        "#    if not param.is_contiguous():\n",
        "#        param.data = param.data.contiguous()"
      ],
      "metadata": {
        "id": "AQytjdcFXMSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clears any logs from previous runs\n",
        "!rm -rf ./bert_finetuning_logs/\n",
        "\n",
        "# Initializes a new Weights & Biases Run\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "run = wandb.init(\n",
        "    name=f\"steam-reviews-finetuning-run-{current_time}\",\n",
        "    project=f'{checkpoint}-finetuned-steam-reviews',\n",
        "    sync_tensorboard=True\n",
        ")\n",
        "\n",
        "# Runs the finetuning/training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LDBipFmYNCGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "p-A3ZbmTNDiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090a9859-f8ec-421c-a166-e91a5094fc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /home/samuel/kaggle/finetuned_models/xlnet-base-cased-finetuned-steam-reviews\n",
            "Configuration saved in /home/samuel/kaggle/finetuned_models/xlnet-base-cased-finetuned-steam-reviews/config.json\n",
            "Model weights saved in /home/samuel/kaggle/finetuned_models/xlnet-base-cased-finetuned-steam-reviews/model.safetensors\n",
            "tokenizer config file saved in /home/samuel/kaggle/finetuned_models/xlnet-base-cased-finetuned-steam-reviews/tokenizer_config.json\n",
            "Special tokens file saved in /home/samuel/kaggle/finetuned_models/xlnet-base-cased-finetuned-steam-reviews/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "hqEOYm0jNlSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the tensorboard jupyter extension\n",
        "# Tensorboard Dashboard also available at http://localhost:6006/\n",
        "# (Sometimes only shows up at localhost URL, not in Jupyter Notebook)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /home/samuel/kaggle/bert_finetuning_logs/"
      ],
      "metadata": {
        "id": "vjhbJx0S9awa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}